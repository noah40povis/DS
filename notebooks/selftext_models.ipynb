{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Initial testing on a naive bayes classifier yielded about 56% accuracy. \n",
    " we used a reduced set to train the model  due to time constraints. \n",
    " \n",
    " further explorations will attempt to improve on this baseline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/dliu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from numpy import random\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##get the data into pandas for analysis\\\"\\\"\\\"\\n\",\n",
    "df = pd.read_csv('rspct.tsv', sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced = df.sample(frac=.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = pd.read_csv('reduced30k.tsv','\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced.to_csv('reduced30k.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = reduced['subreddit'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HomeDepot', 'DunderMifflin', 'hometheater', 'EnterTheGungeon',\n",
       "       'bigboobproblems', 'cinematography', 'Tinder', 'LearnJapanese',\n",
       "       'futarp', 'OnePieceTC', 'Firefighting', 'fleshlight', 'lotr',\n",
       "       'knifeclub', 'sociopath', 'bleach', 'SCCM', 'GhostRecon',\n",
       "       'Ayahuasca', 'codes', 'preppers', 'grammar', 'NewSkaters',\n",
       "       'Truckers', 'southpark', 'Dreams', 'JUSTNOMIL', 'bigdickproblems',\n",
       "       'EternalCardGame', 'evangelion', 'mercedes_benz', 'Cuckold',\n",
       "       'writing', 'afinil', 'synology', 'thinkpad', 'MDMA', 'sailing',\n",
       "       'cfs', 'siacoin', 'ASUS', 'OccupationalTherapy', 'biology',\n",
       "       'thelastofus', 'lonely', 'swrpg', 'acting', 'transformers',\n",
       "       'vergecurrency', 'Beekeeping'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:50].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30390, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = reduced.sample(frac=.1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classes have been balanced! time to clean some of the punctation, and pseudo html from the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def clean_text(X):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "    BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    \n",
    "    X = X.map(lambda t : BeautifulSoup(t, \"lxml\").text) # strip html tags\n",
    "    X = X.map(lambda t : t.lower()) # lowercase text\n",
    "    X = X.map(lambda t : REPLACE_BY_SPACE_RE.sub(' ', t))  # symbols by space in text\n",
    "    X = X.map(lambda t : BAD_SYMBOLS_RE.sub('', t)) # delete symbols which are in BAD_SYMBOLS_RE\n",
    "    X = X.map(lambda t : ' '.join(word for word in t.split() if word not in STOPWORDS))# delete stopwords\n",
    "    return X\n",
    "\n",
    "\n",
    "text_transformer = FunctionTransformer(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we can consider if we want to prepend the title to the post, or handel it as a separate feature. i think for simplicity, the first time, we will just use the post only then compare to results with title + selftext "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df['title'].str.cat(df['selftext'], sep=' ')\n",
    "X = df.selftext\n",
    "y = df.subreddit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import SVC\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trans_pipe = Pipeline([\n",
    "            ('clean', text_transformer),\n",
    "              ('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer())  ## pay attn to transformer vs vectorizer\n",
    "            ])\n",
    "X_trans = trans_pipe.fit_transform(X1)        ## should be able to save this for later\n",
    "X_train,  X_test, y_train,y_test = train_test_split(X_trans,y,test_size=.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24312, 157656), (24312,), (6078, 157656), (6078,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,  y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "              random_state=42, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup pipeline and fit\n",
    "\n",
    "sgd =  SGDClassifier(loss='hinge',\n",
    "                penalty='l2',\n",
    "                alpha=1e-3,\n",
    "                random_state=42, \n",
    "                max_iter=5, \n",
    "                tol=None)\n",
    "sgd.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6140177690029615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dliu/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1206: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dliu/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1206: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "class_rep = classification_report(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize search CV for SVc\n",
    "\n",
    "# C\n",
    "C = [.01, .1]\n",
    "\n",
    "# gamma\n",
    "gamma = [ .001, .01, .1, 1, 10]\n",
    "\n",
    "# degree\n",
    "degree = [ 3, 4, 5]\n",
    "\n",
    "# kernel\n",
    "kernel = ['linear',  'poly']\n",
    "\n",
    "probability = [True]\n",
    "\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'C': C,\n",
    "              'kernel': kernel,\n",
    "              'gamma': gamma,\n",
    "              'degree': degree,\n",
    "               'probability': probability\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed: 58.4min\n"
     ]
    }
   ],
   "source": [
    "pipe = SVC(random_state=8)\n",
    "# Definition of the random search\n",
    "random_search = RandomizedSearchCV(pipe,\n",
    "                                   param_distributions=random_grid,\n",
    "                                   n_iter=10,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=3, \n",
    "                                   verbose=5, \n",
    "                                   random_state=8,\n",
    "                                   n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"The best hyperparameters from Random Search are:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "C = [.0001, .001, .01, .1]\n",
    "degree = [3, 4, 5]\n",
    "gamma = [1, 10, 100]\n",
    "probability = [True]\n",
    "\n",
    "param_grid = [\n",
    "  {'C': C, 'kernel':['linear'], 'probability':probability},\n",
    "  {'C': C, 'kernel':['poly'], 'degree':degree, 'probability':probability},\n",
    "  {'C': C, 'kernel':['rbf'], 'gamma':gamma, 'probability':probability}\n",
    "]\n",
    "\n",
    "# Create a base model\n",
    "svc = svm.SVC(random_state=8)\n",
    "\n",
    "# Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
    "cv_sets = ShuffleSplit(n_splits = 3, test_size = .33, random_state = 8)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=svc, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=cv_sets,\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once we have trained the best model we can get conditional probabilities as well as the prediction: \n",
    "\n",
    "The conditional class probabilities can be obtained by typing:\n",
    "\n",
    "    svc_pred = best_svc.predict_proba(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definition of the random search\n",
    "random_search = RandomizedSearchCV(SVC(random_state=8),\n",
    "                                   param_distributions=random_grid,\n",
    "                                   n_iter=10,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=3, \n",
    "                                   verbose=4, \n",
    "                                   random_state=8)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_trans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"The best hyperparameters from Random Search are:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = sv\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "class_rep = classification_report(y_test, y_pred,target_names=my_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_labels = df['subreddit'].drop_duplicates()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "class_rep = classification_report(y_test, y_pred,target_names=my_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "print(class_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "with open('sgdb_joblib.pkl', 'wb') as f:\n",
    "    joblib.dump(pipe, f, compress=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following to load this model elsewhere:\n",
    "\n",
    "    with open('nb_self', 'rb') as handle:\n",
    "        model = pickle.load(handle)\n",
    "    \n",
    "    model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
